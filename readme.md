

This is a PyTorch implementation of Transformer in **"Attention is All You Need"** (Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin, arxiv, 2017).

This is a just a practice of building model from sractch.
Performance is not optimized.
It may be slow then other implementation.

Checkout test_usage.py to see the usage.

